<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Prototypings | Wonse Jo</title> <meta name="author" content="Wonse Jo"> <meta name="description" content="This page introduce robotics hardware platforms I developed for research in Ph.D. degree from 2017 to now."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/ws_head.png"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://wonsu0513.github.io/prototypings/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Wonse Jo</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item active"> <a class="nav-link" href="/prototypings/">Prototypings<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Prototypings</h1> <p class="post-description">This page introduce robotics hardware platforms I developed for research in Ph.D. degree from 2017 to now.</p> </header> <article> <h4> <b> 1. ROS-based Multi-robot Testbed </b> </h4> <div id="container"> <img class="center" src="/assets/img/platforms/mrs_testbed.jpg" alt="" title="Multi-robot Testbed" style="float: none;height: 100%; width: 100%; object-fit: contain"> <figcaption class="figure-caption text-center"> [ROS-based Mobile Testbed for Multi-robot System.]</figcaption> <br> <p>We present a new multi-robot system as a means of creating a visual communication cue that can add dynamic illustration to static figures or diagrams to enhance the power of delivery and improve an audience's attention. The proposed idea is that when a presenter/speaker writes something such as a shape or letter on a whiteboard table, multiple mobile robots trace the shape or letter while dynamically expressing it. The dynamic movement of multi-robots will further stimulate the cognitive perception of the audience with handwriting, positively affecting the comprehension of content. To do this, we apply image processing algorithms to extract feature points from a handwritten shape or letter while a task allocation algorithm deploys multi-robots on the feature points to highlight the shape or letter. We present preliminary experiment results that verify the proposed system with various characters and letters such as the English alphabet.</p> <ul> <li>Videos:(1) Testbed: <a href="https://youtu.be/i6HtzHSfXWg" target="_blank" rel="external nofollow noopener">https://youtu.be/i6HtzHSfXWg​​</a>​, and (2) User study: <a href="https://youtu.be/E0ETeqvvxPk%E2%80%8B%E2%80%8B/" target="_blank" rel="external nofollow noopener">https://youtu.be/E0ETeqvvxPk​​</a> </li> <li>Papers:(1) Ahreum Lee, <b>Wonse Jo</b>, Shyam Sundar Kannan &amp; Byung-Cheol Min (2021) Investigating the Effect of Deictic Movements of a Multi-Robot, International Journal of Human–Computer Interaction, 37:3, 197-210, DOI: 10.1080/10447318.2020.1812908 ; <a href="https://www.tandfonline.com/doi/full/10.1080/10447318.2020.1812908%E2%80%8B" target="_blank" rel="external nofollow noopener">Link​​</a>, and (2) <b>Wonse Jo</b>, J. H. Park, S. Lee, A. Lee and B. Min, "Design of a Human Multi-Robot Interaction Medium of Cognitive Perception," <i>2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)</i>, 2019, pp. 652-653, doi: 10.1109/HRI.2019.8673188; <a href="https://ieeexplore.ieee.org/abstract/document/8673188%E2%80%8B" target="_blank" rel="external nofollow noopener">Link​​</a> </li> </ul> </div> <h4> <b> 2. Opensource ROS2 Mobile Robot Platform: SMARTmBOT </b> </h4> <div id="container"> <img class="center" src="/assets/img/platforms/smartmbot.jpg" alt="" title="Multi-robot Platform: SMARTmBOT" style="float: none;height: 100%; width: 100%; object-fit: contain"> <figcaption class="figure-caption text-center"> [ROS2-based Mobile Robot Platform for Mutli-robot System, called SMARTmBOT.]</figcaption> <br> <p>We develop SMARTmBot, an open-source, low-cost mobile robot platform that can facilitate the research and education involving multi-robot systems. SMARTmBot runs on Robot Operating System (ROS) 2, using Raspberry Pi 4 as the mainboard computer. The hardware is composed of 3 layers of PCB, including various input and output devices. SMARTmBots as a swarm can form different types of formations, change their light either individually or as a whole, and measure the distance of nearby obstacles. In the future, we will utilize this platform to investigate the effects of a swarm/multi-robot on human perception and cognition. In addition, we will enable K-12 teachers and students to access this robot platform to promote their education and interests in STEM.​</p> <ul> <li> Repository: <a href="https://github.com/SMARTlab-Purdue/SMARTmBOT%E2%80%8B%E2%80%8B" target="_blank" rel="external nofollow noopener"> https://github.com/SMARTlab-Purdue/SMARTmBOT​​​​​</a>​</li> <li> Video: <a href="https://youtu.be/cn3vcqFgf90%E2%80%8B" target="_blank" rel="external nofollow noopener">https://youtu.be/cn3vcqFgf90​​​​</a>​</li> <li> Paper: <b>Wonse Jo</b>, Jaeeun Kim, and Byung-Cheol Min, ``ROS2 Open-Source Swarm Robot Platform: SMARTmBot,'' <i>2021 International Conference on Robotics and Automation (ICRA)</i>, Workshop on Robot Swarms in the Real World: From Design to Deployment - Live Demonstration, Xi'an, China, May 30 - June 5, 2021.​ </li> </ul> </div> <h4> <b> 3. Environmental Unmannded Surfce Vessles: SMARTmBOAT series </b> </h4> <h5> <b> (a) SMARTmBOAT-03 </b> </h5> <div id="container"> <img class="center" src="/assets/img/platforms/smartmboat-03.jpg" alt="" title="Water Monitoring USV Platform" style="float: none;height: 100%; width: 100%; object-fit: contain"> <figcaption class="figure-caption text-center"> [ROS-based Opensource Unmanned Surface Vehicle (USV) for water montioring, called SMARTmBOAT-03.]</figcaption> <br> <p>We propose a new, fully open-source, low-cost, and small-sized Unmanned Surface Vehicle (USV) for measuring near-surface water quality in real time in various environments. Existing commercial USVs are expensive and not fully based on open-source hardware, making it difficult to purchase them and to modify their designs and programming to suit various environments. In contrast, the USV platform proposed in this paper is completely open-source, from hardware to software; most parts of the platform can be 3D-printed, and it can be easily modified and upgraded in terms of both design and programming. The platform is equipped with off-the-shelf water sensors for acquiring data like as pH, turbidity, and temperature to measure water quality in real water resources (such as ponds, reservoirs, and lakes). Furthermore, we provide an Android application through which users can easily control the USV via Bluetooth and display the sensor and GPS data the platform generates. We validated the performance of the platform in terms of usability, mobility, and stability through field experiments in various locations, including both the USA and Peru. Moreover, we present a potential application and approach in which this platform can navigate autonomously by utilizing the Robot Operating System (ROS) and Bluetooth protocols.</p> <ul> <li> Repository: <a href="https://osf.io/wsnrt/%E2%80%8B%E2%80%8B%E2%80%8B" target="_blank" rel="external nofollow noopener"> https://osf.io/wsnrt/​​​​​​​​</a>​</li> <li> Video: <a href="https://youtu.be/OBqA9pRZ8pM%E2%80%8B" target="_blank" rel="external nofollow noopener">https://youtu.be/OBqA9pRZ8pM​​​​​</a>​</li> <li> Paper: <b>Wonse Jo</b>, Hoashi, Y., Aguilar, L. L. P., Postigo-Malaga, M., Garcia-Bravo, J. M., &amp; Min, B. C. (2019). A low-cost and small USV platform for water quality monitoring. <i>HardwareX</i>, 6, e00076; <a href="https://www.sciencedirect.com/science/article/pii/S2468067219300367?via%3Dihub%E2%80%8B" target="_blank" rel="external nofollow noopener">Link​​</a> </li> </ul> </div> <h5> <b> (a) SMARTmBOAT-04 </b> </h5> <div id="container"> <img class="center" src="/assets/img/platforms/smartmboat-04.jpg" alt="" title="Reversible USV Platform" style="float: none;height: 100%; width: 100%; object-fit: contain"> <figcaption class="figure-caption text-center"> [ROS2-based Opensource Unmanned Surface Vehicle (USV) for water montioring, called SMARTmBOAT-04.]</figcaption> <br> <p>We propose a new and small USV platform to overcome the limitations of existing robot systems. The main feature of the proposed USV is that it is designed as a vertically symmetrical structure, so that it can continuously perform its mission even when the USV is capsized. Moreover, the USV system can automatically check whether the robot has been capsized via GPS and IMU sensors installed on the USV, and carry out the mission regardless of whether it is overturned, by controlling three waterproof servo motors according to the USV’s orientation, to rotate two main thrusters and the water sensor module. The USV measures water quality and depth in real-time through a Total Dissolved Solids (TDS) sensor, a temperature sensor, and a Ping sensor that measures water depth. A forward-facing camera allows the USV to autonomously avoid obstacles using computer vision. All data is transmitted in real-time to the user interface or main system using Robot Operating System 2 (ROS2), the latest robot middleware that supports real-time control.​</p> <ul> <li> Poster: <b>Wonse Jo</b>, Pou hei Chan, Chad T. Jafvert, Mauricio Postigo-Malaga, and Byung-Cheol Min, "Development of a Vertically Symmetrical Unmanned Surface Vessel (VSUSV) for Bathymetric and Water Quality Surveys of Surface Waters," <i>2020 the 7th Annual C4E Environmental Community Mixer, Purdue University</i>, Oct. 2020.</li> </ul> </div> <h5> <b> (a) SMARTmBOAT-05 </b> </h5> <div id="container"> <img class="center" src="/assets/img/platforms/smartmboat-05.jpg" alt="" title="Alage Removal USV Platform" style="float: none;height: 100%; width: 100%; object-fit: contain"> <figcaption class="figure-caption text-center"> [Low-cost Algae Removal Unmanned Surface Vehicle (USV) Platform, called SMARTmBOAT-05.]</figcaption> <br> <p>We introduce a small and low-cost unmanned surface vehicle (USV), the SMARTBoat 5, capable of removing harmful algal blooms (HABs), which are a rising environmental issue worldwide. The developed USV is a hovercraft type, operated by two propellers with duct fans; it is able to freely move even in shallow water and to approach shorelines. For eco-friendly, immediate, and safe control of algae, the USV is equipped with a novel water suction mechanism that enables it to actively collect algae without physical contact. In addition, it is equipped with a mesh net-based algae filter system that is easily disassembled and replaced. The USV system is supported by the Robot Operating System (ROS) for expandability and use in diverse applications. The performance of the proposed water suction mechanism and USV platform overall are validated through computational fluid simulation (CFD) and experiments in both lab and real environments.​​</p> <ul> <li> Repository: <a href="https://github.com/SMARTlab-Purdue/Harmful-Algae-Removal-USV%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B" target="_blank" rel="external nofollow noopener"> https://github.com/SMARTlab-Purdue/Harmful-Algae-Removal-USV​​​​​​​​​</a>​</li> <li> Video: <a href="https://youtu.be/8BPvFbJgXho%E2%80%8B" target="_blank" rel="external nofollow noopener">https://youtu.be/8BPvFbJgXho​</a>​</li> <li> Paper: <b>Wonse Jo</b>, J. Park, Y. Hoashi and B. Min, "Development of an Unmanned Surface Vehicle for Harmful Algae Removal," <i>OCEANS 2019 MTS/IEEE SEATTLE</i>, 2019, pp. 1-7, doi: 10.23919/OCEANS40490.2019.8962677; <a href="https://ieeexplore.ieee.org/document/8962677" target="_blank" rel="external nofollow noopener">Link​​</a> </li> </ul> </div> <h4> <b> 3. Anti-noise Tapping Sound Generator and prediction </b> </h4> <div id="container"> <img class="center" src="/assets/img/platforms/tapping_generator.jpg" alt="" title="Anti-noise Tapping Sound Generator" style="float: none;height: 100%; width: 100%; object-fit: contain"> <figcaption class="figure-caption text-center"> [Anti-noise Tapping Sound Generator to Recognize Unknown Material Types.]</figcaption> <br> <p>For recognizing unknown material in search and recuse environment, we developed the anti-noise tapping sound generator that is making and recognizing the tapping sound to estimate types of the material. The system have two microphones and a solenoid. The two microphones are to reduce environmental noise for recording only tapping sound generated by the solenoid. Finally, the system was able to estimate types of following materials using MFCCs and SVM: cardboard, glass, metal, plastic, wall, wood, and empty.​</p> <ul> <li>Video: <a href="https://youtu.be/4VGntBByJWE" target="_blank" rel="external nofollow noopener">https://youtu.be/4VGntBByJWE​​</a>​</li> <li>Paper: S. Kannan, <b>Wonse Jo</b>, R. Parasuraman and B. -C. Min, "Material Mapping in Unknown Environments using Tapping Sound," <i>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i>, 2020, pp. 4855-4861, doi: 10.1109/IROS45743.2020.9341346; <a href="http://ras.papercept.net/images/temp/IROS/files/2147.pdf%E2%80%8B" target="_blank" rel="external nofollow noopener">Link​​</a> </li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Wonse Jo. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>